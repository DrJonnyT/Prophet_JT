{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prophet_JT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9DxR8RS9HOSYXRlRUqDwZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrJonnyT/Prophet_JT/blob/main/Prophet_JT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGVviCbUXP8C",
        "outputId": "1dc9ae3d-4fb0-4a4b-c449-8e5fad003ac9"
      },
      "source": [
        "#!git clone https://github.com/DrJonnyT/Prophet_JT.git\r\n",
        "%ls\r\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mProphet_JT\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv8tunXDUo_H"
      },
      "source": [
        "##########################################################################################\r\n",
        "#    Script to fit and predict using the Facebook time series model                      #\r\n",
        "#    Also includes ability to plot diurnal profile comparisons                           #\r\n",
        "#                                                                                        #\r\n",
        "#    This is free software: you can redistribute it and/or modify it under               #\r\n",
        "#    the terms of the GNU General Public License as published by the Free Software       #\r\n",
        "#    Foundation, either version 3 of the License, or (at your option) any later          #\r\n",
        "#    version.                                                                            #\r\n",
        "#                                                                                        #\r\n",
        "#    This is distributed in the hope that it will be useful, but WITHOUT                 #\r\n",
        "#    ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS       #\r\n",
        "#    FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more              #\r\n",
        "#    details.                                                                            #\r\n",
        "#                                                                                        #\r\n",
        "#    You should have received a copy of the GNU General Public License along with        #\r\n",
        "#    this repository.  If not, see <http://www.gnu.org/licenses/>.                       #\r\n",
        "#                                                                                        #\r\n",
        "##########################################################################################\r\n",
        "# 2020, author David Topping: david.topping@manchester.ac.uk\r\n",
        "\r\n",
        "#import pyreadr\r\n",
        "import os.path\r\n",
        "import os\r\n",
        "import requests\r\n",
        "#import pdb\r\n",
        "#import wget\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import datetime\r\n",
        "import sys\r\n",
        "from pathlib import Path\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from fbprophet import Prophet\r\n",
        "from fbprophet.plot import add_changepoints_to_plot\r\n",
        "from fbprophet.diagnostics import cross_validation\r\n",
        "from fbprophet.diagnostics import performance_metrics\r\n",
        "from fbprophet.plot import plot_cross_validation_metric\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbIS4jp6U0D7"
      },
      "source": [
        "\r\n",
        "# In this file we first pull all of the data from the DEFRA portal before fitting\r\n",
        "# prophet models to each site. This is currently the same as a seperate Script\r\n",
        "# for downloaded and analysing the DEFRA data here:\r\n",
        "# https://github.com/loftytopping/DEFRA_Air_Quality_data\r\n",
        "# The plan is to make this generic for any air quality data\r\n",
        "\r\n",
        "# Also please note that in this file we are testing the Vanilla Prophet model\r\n",
        "# The sensitivity to hyperameters and periods of fitting are reserved for the\r\n",
        "# individual site analysis\r\n",
        "\r\n",
        "#################################################################################\r\n",
        "# Load an existing .csv file with air quality data for fitting. In this example\r\n",
        "# this includes\r\n",
        "\r\n",
        "# if 'google.colab' in str(get_ipython()):\r\n",
        "#     data = pd.read_csv('https://raw.githubusercontent.com/DrJonnyT/Prophet_JT/main/MAN3.csv')\r\n",
        "#     data.head()\r\n",
        "# else:\r\n",
        "#data = pd.read_csv(\"data/PM25_China_annual.csv\") \r\n",
        "#data.head()\r\n",
        "\r\n",
        "\r\n",
        "frame_aq = pd.read_csv(r'Prophet_JT/MAN3.csv')\r\n",
        "frame_aq['datetime'] = pd.to_datetime(frame_aq['date'])\r\n",
        "frame_aq = frame_aq.sort_values(by='datetime',ascending=True)\r\n",
        "frame_aq=frame_aq.set_index('datetime')\r\n",
        "#pdb.set_trace()\r\n",
        "#################################################################################\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqlx_q9gVGwG"
      },
      "source": [
        "\r\n",
        "################################################################################\r\n",
        "# Now load the traffic data from TfGM_Drakewell\r\n",
        "\r\n",
        "# These files give us an insight into representiveness of traffic data\r\n",
        "# The following data is from the closes 'Journey Time' BLU measurement point to\r\n",
        "# the AURN site.\r\n",
        "frame_traff = pd.read_csv(r'pvr_2016-01-01_1597d_portland.csv')\r\n",
        "# The additional option below is for a site on Portland street but away from Piccadilly Gardens\r\n",
        "#frame_traff = pd.read_csv(r'C:\\Users\\Dave\\Documents\\Code\\Developing\\Traffic_analysis\\TfGM_Drakewell\\pvr_2016-01-01_1597d_1.csv')\r\n",
        "\r\n",
        "# Extract data from Channel 1\r\n",
        "frame_traff=frame_traff[frame_traff['LaneDescription']=='Channel 1']\r\n",
        "frame_traff['datetime'] = pd.to_datetime(frame_traff['Sdate'])\r\n",
        "frame_traff = frame_traff.sort_values(by='datetime',ascending=True)\r\n",
        "frame_traff=frame_traff.set_index('datetime')\r\n",
        "\r\n",
        "\r\n",
        "# Now merge the two dataframes, both Air Quality and Traffic, on the time index\r\n",
        "combined_df=pd.merge(frame_traff,frame_aq, left_index=True, right_index=True)\r\n",
        "#remove duplicate entries in the index (downloaded multiple CSV files with overlapping times)\r\n",
        "combined_df = combined_df.loc[~combined_df.index.duplicated(keep='first')]\r\n",
        "\r\n",
        "\r\n",
        "#Now produce a box-plot for all entries in dataset.\r\n",
        "combined_df[\"NO2\"] = pd.to_numeric(combined_df[\"NO2\"])\r\n",
        "combined_df[\"O3\"] = pd.to_numeric(combined_df[\"O3\"])\r\n",
        "combined_df[\"Volume\"] = pd.to_numeric(combined_df[\"Volume\"])\r\n",
        "combined_df[\"NO2 per Volume\"]=combined_df[\"NO2\"]/combined_df[\"Volume\"]\r\n",
        "combined_df[\"log NO2 per Volume\"]=np.log(combined_df[\"NO2\"]/combined_df[\"Volume\"])\r\n",
        "\r\n",
        "f, ax = plt.subplots(2,1,figsize=(6, 5))\r\n",
        "ax[1].plot(combined_df.resample('D').mean().index, combined_df['log NO2 per Volume'].resample('D').mean(), color='r')\r\n",
        "#ax = f.gca()\r\n",
        "ax[1].set(xlabel='Date', ylabel=r\"Log(NO2/Volume) $\\mu g.m^{-3}$\")\r\n",
        "ax[1].set_xlim([datetime.date(2019, 9, 28), datetime.date(2020, 5, 10)])\r\n",
        "#ax[1].xlabel(\"Date\")\r\n",
        "#ax[1].ylabel(\"Log(NO2/Traffic Volume)\")\r\n",
        "ax[0].plot(combined_df.resample('D').mean().index, combined_df['Volume'].resample('D').mean(), color='r')\r\n",
        "#ax = f.gca()\r\n",
        "ax[0].set_xlim([datetime.date(2019, 9, 28), datetime.date(2020, 5, 10)])\r\n",
        "ax[0].set(ylabel=r\"Volume [$hr^{-1}$]\")\r\n",
        "plt.show()\r\n",
        "plt.close('all')\r\n",
        "\r\n",
        "\r\n",
        "# Mask to look at typical diurnal profiles before COVID19 lockdown\r\n",
        "mask_pre_lockdown = (combined_df.index < '2020-3-23')\r\n",
        "f, ax = plt.subplots(3,1,figsize=(12, 5))\r\n",
        "sns.boxplot(x=combined_df.loc[mask_pre_lockdown].index.hour, y=combined_df.loc[mask_pre_lockdown]['NO2'],ax=ax[0])\r\n",
        "sns.boxplot(x=combined_df.loc[mask_pre_lockdown].index.hour, y=combined_df.loc[mask_pre_lockdown]['O3'],ax=ax[1])\r\n",
        "sns.boxplot(x=combined_df.loc[mask_pre_lockdown].index.hour, y=combined_df.loc[mask_pre_lockdown]['log NO2 per Volume'],ax=ax[2])\r\n",
        "plt.show()\r\n",
        "plt.close('all')\r\n",
        "#pdb.set_trace()\r\n",
        "\r\n",
        "# Now produce a set of two combined box-plots according to April before 2020 and for 2020\r\n",
        "mask_tag = (combined_df.index.month == 4) & (combined_df.index > '2019-12-30')\r\n",
        "combined_df['April_2020'] = mask_tag\r\n",
        "booleanDictionary = {True: 'TRUE', False: 'FALSE'}\r\n",
        "f, ax = plt.subplots(4,1,figsize=(15, 15))\r\n",
        "mask3 = (combined_df.index.month == 4)\r\n",
        "sns.boxplot(data=combined_df.loc[mask3],x=combined_df.loc[mask3].index.hour, y=combined_df.loc[mask3]['NO2'],hue='April_2020', ax=ax[0])\r\n",
        "sns.boxplot(data=combined_df.loc[mask3],x=combined_df.loc[mask3].index.hour, y=combined_df.loc[mask3]['O3'],hue='April_2020',ax=ax[1])\r\n",
        "sns.boxplot(data=combined_df.loc[mask3],x=combined_df.loc[mask3].index.hour, y=combined_df.loc[mask3]['Volume'],hue='April_2020',ax=ax[2])\r\n",
        "sns.boxplot(data=combined_df.loc[mask3],x=combined_df.loc[mask3].index.hour, y=combined_df.loc[mask3]['log NO2 per Volume'],hue='April_2020',ax=ax[3])\r\n",
        "ax[0].tick_params(axis='x', which='both', bottom='off',labelbottom='off')\r\n",
        "ax[1].tick_params(axis='x', which='both', bottom='off',labelbottom='off')\r\n",
        "ax[2].tick_params(axis='x', which='both', bottom='off',labelbottom='off')\r\n",
        "plt.show()\r\n",
        "plt.close('all')\r\n",
        "#pdb.set_trace()\r\n",
        "\r\n",
        "\r\n",
        "######################  Train a Prophet instance to the NO2 per traffic volume ###########################\r\n",
        "train_dataset2= pd.DataFrame()\r\n",
        "train_dataset2['ds'] = (pd.to_datetime(combined_df['Sdate']))\r\n",
        "train_dataset2['O3']=combined_df['O3']\r\n",
        "train_dataset2['y']=combined_df['log NO2 per Volume']\r\n",
        "#train_dataset2['y']=combined_df['NO2 per Volume']\r\n",
        "train_dataset2['Modelled Wind Direction']=combined_df['wd']\r\n",
        "train_dataset2['Modelled Wind Speed']=combined_df['ws']\r\n",
        "train_dataset2['Modelled Temperature']=combined_df['temp']\r\n",
        "train_dataset2['Traffic Volume']=combined_df['Volume']\r\n",
        "train_dataset2['NO2']=combined_df['NO2']\r\n",
        "train_dataset2 = train_dataset2[train_dataset2.ds != 'End']\r\n",
        "train_dataset2 = train_dataset2[train_dataset2['O3'] != 'No data']\r\n",
        "train_dataset2 = train_dataset2[train_dataset2['y'] != 'No data']\r\n",
        "train_dataset2 = train_dataset2[train_dataset2['Modelled Wind Direction'] != 'No data']\r\n",
        "train_dataset2 = train_dataset2[train_dataset2['Modelled Wind Speed'] != 'No data']\r\n",
        "train_dataset2 = train_dataset2[train_dataset2['Modelled Temperature'] != 'No data']\r\n",
        "train_dataset2=train_dataset2.replace([np.inf, -np.inf], np.nan)\r\n",
        "train_dataset2.dropna(inplace=True)\r\n",
        "pro_regressor2= Prophet()\r\n",
        "# Add additional regressors\r\n",
        "pro_regressor2.add_regressor('Modelled Wind Direction')\r\n",
        "pro_regressor2.add_regressor('Modelled Wind Speed')\r\n",
        "pro_regressor2.add_regressor('Modelled Temperature')\r\n",
        "#pro_regressor2.add_regressor('Traffic Volume')\r\n",
        "mask_reg1b = (train_dataset2.ds < '2020-3-01')\r\n",
        "mask_reg2b = (train_dataset2.ds >= '2020-3-01')\r\n",
        "mask_reg3b = (train_dataset2.ds >= '2020-3-25')\r\n",
        "mask_futureb = (train_dataset2.ds > '2019-12-01')\r\n",
        "\r\n",
        "# Specify a train and test dataset. Train before March 2020\r\n",
        "train_X2= train_dataset2.loc[mask_reg1b]\r\n",
        "test_X2= train_dataset2.loc[mask_reg2b]\r\n",
        "\r\n",
        "pro_regressor2.fit(train_X2)\r\n",
        "forecast_data2 = pro_regressor2.predict(test_X2)\r\n",
        "# From the forecast log(No2/Volume), use the traffic data to predict the levels of NO2\r\n",
        "forecast_data2['NO2 from volume']=np.exp(forecast_data2['yhat'].values)*test_X2['Traffic Volume'].values\r\n",
        "forecast_data2['NO2 from volume upper']=np.exp(forecast_data2['yhat_upper'].values)*test_X2['Traffic Volume'].values\r\n",
        "forecast_data2['NO2 from volume lower']=np.exp(forecast_data2['yhat_lower'].values)*test_X2['Traffic Volume'].values\r\n",
        "\r\n",
        "# Now plot the 'business as usual' NO2 per volume versus the actual calculated from combining\r\n",
        "# the AURN data and traffic data\r\n",
        "fig =pro_regressor2.plot(forecast_data2, uncertainty=True,figsize=(15, 5))\r\n",
        "axes = fig.get_axes()\r\n",
        "plt.plot(train_dataset2.loc[mask_reg2b]['ds'], train_dataset2.loc[mask_reg2b]['y'], color='r', label='actual')\r\n",
        "ax = fig.gca()\r\n",
        "ax.set_xlim([datetime.date(2020, 2, 28), datetime.date(2020, 5, 10)])\r\n",
        "ax.set_ylim([-4, 1.5])\r\n",
        "axes[0].set_xlabel('Date')\r\n",
        "axes[0].set_ylabel('log (NO2 / Traffic volume)')\r\n",
        "plt.title('Validation data v. forecast - log NO2 / Traffic volume')\r\n",
        "plt.legend();\r\n",
        "plt.show()\r\n",
        "plt.close('all')\r\n",
        "#pdb.set_trace()\r\n",
        "#########################################################################################\r\n",
        "\r\n",
        "###########  Train to predict NO2, as per our standard Propher use  #########################\r\n",
        "# Now fit two prophet models, one to the just met data and one to the traffic\r\n",
        "train_dataset= pd.DataFrame()\r\n",
        "train_dataset['ds'] = (pd.to_datetime(combined_df['Sdate']))\r\n",
        "train_dataset['O3']=combined_df['O3']\r\n",
        "train_dataset['y']=combined_df['NO2']\r\n",
        "train_dataset['Modelled Wind Direction']=combined_df['wd']\r\n",
        "train_dataset['Modelled Wind Speed']=combined_df['ws']\r\n",
        "train_dataset['Modelled Temperature']=combined_df['temp']\r\n",
        "train_dataset['Traffic Volume']=combined_df['Volume']\r\n",
        "train_dataset['NO2 per Volume']=combined_df['NO2 per Volume']\r\n",
        "train_dataset = train_dataset[train_dataset.ds != 'End']\r\n",
        "train_dataset = train_dataset[train_dataset['O3'] != 'No data']\r\n",
        "train_dataset = train_dataset[train_dataset['y'] != 'No data']\r\n",
        "train_dataset = train_dataset[train_dataset['Modelled Wind Direction'] != 'No data']\r\n",
        "train_dataset = train_dataset[train_dataset['Modelled Wind Speed'] != 'No data']\r\n",
        "train_dataset = train_dataset[train_dataset['Modelled Temperature'] != 'No data']\r\n",
        "train_dataset=train_dataset.replace([np.inf, -np.inf], np.nan)\r\n",
        "train_dataset.dropna(inplace=True)\r\n",
        "mask_reg1 = (train_dataset.ds < '2020-3-01')\r\n",
        "mask_reg2 = (train_dataset.ds >= '2020-3-01')\r\n",
        "mask_reg3 = (train_dataset.ds >= '2020-3-25')\r\n",
        "mask_future = (train_dataset.ds > '2019-12-01')\r\n",
        "\r\n",
        "# Build a regressor [using a changpoint scale inferred from the Cross Validation studies]\r\n",
        "pro_regressor= Prophet(changepoint_prior_scale=10)\r\n",
        "#pro_regressor.add_country_holidays(country_name='UK')\r\n",
        "pro_regressor.add_regressor('Modelled Wind Direction')\r\n",
        "pro_regressor.add_regressor('Modelled Wind Speed')\r\n",
        "pro_regressor.add_regressor('Modelled Temperature')\r\n",
        "train_X= train_dataset.loc[mask_reg1]\r\n",
        "test_X= train_dataset.loc[mask_reg2]\r\n",
        "\r\n",
        "pro_regressor.fit(train_X)\r\n",
        "forecast_data = pro_regressor.predict(test_X)\r\n",
        "\r\n",
        "# Plot the actual data with forecast NO2 AND NO2 from log(NO2/volume) fits\r\n",
        "fig =pro_regressor.plot(forecast_data, uncertainty=True,figsize=(15, 5), xlabel='Date', ylabel=r'NO2 $\\mu g.m^{-3}$')\r\n",
        "plt.plot(train_dataset.loc[mask_reg2]['ds'], train_dataset.loc[mask_reg2]['y'], color='r', label='Measured')\r\n",
        "plt.plot(forecast_data['ds'], forecast_data['yhat'], color='tab:blue', label='Forecast')\r\n",
        "plt.plot(forecast_data2['ds'], forecast_data2['NO2 from volume'], color='g', label='Forecast using traffic data')\r\n",
        "ax = fig.gca()\r\n",
        "ax.set_xlim([datetime.date(2020, 2, 28), datetime.date(2020, 5, 10)])\r\n",
        "ax.set_ylim([0, 120])\r\n",
        "ax.set_xlabel(\"Date\", size=14)\r\n",
        "ax.set_ylabel(r'NO2 $\\mu g.m^{-3}$', size=14)\r\n",
        "ax.tick_params(axis=\"x\", labelsize=14)\r\n",
        "ax.tick_params(axis=\"y\", labelsize=14)\r\n",
        "#plt.title('Validation data v. forecast ')\r\n",
        "plt.legend(prop={\"size\":14});\r\n",
        "plt.show()\r\n",
        "plt.close('all')\r\n",
        "\r\n",
        "# Calculate the % deviation from the predictions based on traffic\r\n",
        "forecast_data2['% deviation']=(forecast_data2['NO2 from volume'].values-forecast_data['yhat'].values)/(forecast_data['yhat'].values)*100.0\r\n",
        "mask_reg4 = (forecast_data2.ds >= '2020-3-25')\r\n",
        "\r\n",
        "# Create a boxplot looking at measured, forecast with and without traffic\r\n",
        "# To do this we are going to concatenate vertically\r\n",
        "forecast_normal_df = forecast_data[['ds','yhat']]\r\n",
        "forecast_normal_new_df = forecast_normal_df.copy()\r\n",
        "forecast_normal_new_df['label'] = 'Forecast'\r\n",
        "forecast_normal_new_df=forecast_normal_new_df.rename(columns={\"yhat\": \"y\"})\r\n",
        "forecast_traffic_df = forecast_data2[['ds','NO2 from volume']]\r\n",
        "forecast_traffic_new_df = forecast_traffic_df.copy()\r\n",
        "forecast_traffic_new_df['label'] = 'Forecast using traffic data'\r\n",
        "forecast_traffic_new_df=forecast_traffic_new_df.rename(columns={\"NO2 from volume\": \"y\"})\r\n",
        "measured_df = train_dataset.loc[mask_reg2][['ds','y']]\r\n",
        "measured_new_df = measured_df.copy()\r\n",
        "measured_new_df['label'] = 'Measured'\r\n",
        "\r\n",
        "vertical_stack = pd.concat([forecast_normal_new_df, forecast_traffic_new_df], axis=0)\r\n",
        "vertical_stack = pd.concat([vertical_stack, measured_new_df], axis=0)\r\n",
        "\r\n",
        "vertical_stack['ds']=pd.to_datetime(vertical_stack['ds'])\r\n",
        "vertical_stack=vertical_stack.set_index('ds')\r\n",
        "# Now set the index to be the datetime\r\n",
        "f, ax = plt.subplots(1,1,figsize=(12, 5))\r\n",
        "sns.boxplot(data=vertical_stack,x=vertical_stack.index.hour, y=vertical_stack['y'],hue='label')\r\n",
        "ax.set_xlabel(\"Hour\", size=14)\r\n",
        "ax.set_ylabel(r'NO2 $\\mu g.m^{-3}$', size=14)\r\n",
        "ax.tick_params(axis=\"x\", labelsize=14)\r\n",
        "ax.tick_params(axis=\"y\", labelsize=14)\r\n",
        "#plt.title('Validation data v. forecast ')\r\n",
        "plt.legend(prop={\"size\":14});\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}